{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "965f524b-5fb4-49bf-854b-bc14e418dabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRITEO ATTRIBUTION MODELING - LIGHTGBM\n",
      "=================================================================\n",
      "\n",
      "Loading COMPLETE data...\n",
      "Loaded 16,468,027 impressions\n",
      "\n",
      "Dataset Overview:\n",
      "  Total impressions: 16,468,027\n",
      "  Attribution rate: 2.7%\n",
      "  Challenge: Highly imbalanced dataset\n",
      "\n",
      "Feature Engineering...\n",
      "  Selected 12 features\n",
      "  Added campaign performance and cost quartiles\n",
      "  Total features: 14\n",
      "  Data split: (13174421, 14) train, (3293606, 14) test\n",
      "\n",
      "LIGHTGBM (Fast Gradient Boosting)\n",
      "-----------------------------------------------------------------\n",
      "Training LightGBM...\n",
      "\n",
      "RESULTS - LIGHTGBM (COMPLETE DATASET)\n",
      "-----------------------------------------------------------------\n",
      "ROC-AUC:        0.949\n",
      "Precision:      0.136 (13.6%)\n",
      "Recall:         0.911 (91.1%)\n",
      "F1-Score:       0.236\n",
      "Training Time:  36.4 seconds\n",
      "\n",
      "Confusion Matrix:\n",
      "True Positives:  80,608\n",
      "False Positives: 513,230\n",
      "True Negatives:  2,691,891\n",
      "False Negatives: 7,877\n",
      "Correct:         2,772,499 (84.2%)\n",
      "\n",
      "TOP 10 FEATURE IMPORTANCE:\n",
      "-----------------------------------\n",
      "cat1                 408.0\n",
      "cat3                 402.0\n",
      "campaign_perf        399.0\n",
      "cpo                  360.0\n",
      "cost                 286.0\n",
      "campaign             244.0\n",
      "cat6                 197.0\n",
      "cat5                 197.0\n",
      "cat2                 139.0\n",
      "cat9                 115.0\n",
      "\n",
      "Files ready for next cell (model saved below)...\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "CRITEO ATTRIBUTION MODELING - LIGHTGBM ONLY\n",
    "===========================================\n",
    "\n",
    "LightGBM: Fast, memory-efficient gradient boosting.\n",
    "Production favorite, handles large datasets perfectly.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"CRITEO ATTRIBUTION MODELING - LIGHTGBM\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# Load COMPLETE dataset (ALL ROWS)\n",
    "print(\"\\nLoading COMPLETE data...\")\n",
    "try:\n",
    "    df = pd.read_csv('E:\\\\PROJECT_F\\\\F\\\\criteo_production_ready_data.csv')  # ALL ROWS\n",
    "    print(f\"Loaded {len(df):,} impressions\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Basic info\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"  Total impressions: {len(df):,}\")\n",
    "print(f\"  Attribution rate: {df['attribution'].mean():.1%}\")\n",
    "print(f\"  Challenge: Highly imbalanced dataset\")\n",
    "\n",
    "# Feature selection (production-ready)\n",
    "print(f\"\\nFeature Engineering...\")\n",
    "features = [\n",
    "    'campaign', 'cost', 'cpo', 'click',\n",
    "    'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat8', 'cat9'  # Exclude cat7\n",
    "]\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df['attribution'].copy()\n",
    "\n",
    "print(f\"  Selected {len(features)} features\")\n",
    "#print(f\"  Excluded cat7: {df['cat7'].nunique():,} unique values (too high)\")\n",
    "\n",
    "# Simple feature engineering\n",
    "campaign_perf = df.groupby('campaign')['attribution'].mean()\n",
    "X['campaign_perf'] = X['campaign'].map(campaign_perf).fillna(df['attribution'].mean())\n",
    "X['cost_quartile'] = pd.qcut(X['cost'], q=4, labels=[1,2,3,4]).astype(int)\n",
    "\n",
    "print(f\"  Added campaign performance and cost quartiles\")\n",
    "print(f\"  Total features: {X.shape[1]}\")\n",
    "\n",
    "# Encode categoricals for LightGBM\n",
    "categorical_cols = ['campaign'] + [col for col in X.columns if col.startswith('cat')]\n",
    "X_encoded = X.copy()\n",
    "for col in categorical_cols:\n",
    "    if col in X_encoded.columns:\n",
    "        le = LabelEncoder()\n",
    "        X_encoded[col] = le.fit_transform(X_encoded[col].astype(str))\n",
    "\n",
    "# Split data (stratified for evaluation)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"  Data split: {X_train.shape} train, {X_test.shape} test\")\n",
    "\n",
    "# LIGHTGBM (Fast & Memory Efficient)\n",
    "print(f\"\\nLIGHTGBM (Fast Gradient Boosting)\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=100,        # Balanced for full dataset\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    "    class_weight='balanced',\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=31,\n",
    "    n_jobs=-1,\n",
    "    force_col_wise=True      # Memory optimization\n",
    ")\n",
    "\n",
    "print(\"Training LightGBM...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Train\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = lgb_model.predict(X_test)\n",
    "y_prob = lgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Calculate metrics\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "# Confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Feature importance (top 10)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_encoded.columns,\n",
    "    'importance': lgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(10)\n",
    "\n",
    "# Results\n",
    "print(f\"\\nRESULTS - LIGHTGBM (COMPLETE DATASET)\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"ROC-AUC:        {roc_auc:.3f}\")\n",
    "print(f\"Precision:      {precision:.3f} ({precision:.1%})\")\n",
    "print(f\"Recall:         {recall:.3f} ({recall:.1%})\")\n",
    "print(f\"F1-Score:       {f1:.3f}\")\n",
    "print(f\"Training Time:  {training_time:.1f} seconds\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# CONFUSION MATRIX (CUSTOM FORMAT)\n",
    "# --------------------------------------------------\n",
    "total = tp + tn + fp + fn\n",
    "correct = tp + tn\n",
    "accuracy = correct / total\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(f\"True Positives:  {tp:,}\")\n",
    "print(f\"False Positives: {fp:,}\")\n",
    "print(f\"True Negatives:  {tn:,}\")\n",
    "print(f\"False Negatives: {fn:,}\")\n",
    "print(f\"Correct:         {correct:,} ({accuracy:.1%})\")\n",
    "\n",
    "\n",
    "print(f\"\\nTOP 10 FEATURE IMPORTANCE:\")\n",
    "print(\"-\" * 35)\n",
    "for _, row in feature_importance.iterrows():\n",
    "    print(f\"{row['feature']:<20} {row['importance']:.1f}\")\n",
    "\n",
    "print(f\"\\nFiles ready for next cell (model saved below)...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8274dbc3-27c2-4529-9baa-b01539ac9b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING YOUR TRAINED LIGHTGBM MODEL...\n",
      "==================================================\n",
      "✅ Saved: lightgbm_trained_model.pkl\n",
      "✅ Saved: lightgbm_trained_model.txt (native FAST)\n",
      "✅ Saved: lightgbm_model_info.json\n",
      "\n",
      "PRODUCTION READY!\n",
      "Files created:\n",
      "  lightgbm_trained_model.pkl\n",
      "  lightgbm_trained_model.txt (native)\n",
      "  lightgbm_model_info.json\n",
      "Model: ROC-AUC 0.949 on 16,468,027 rows\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SAVE TRAINED LIGHTGBM MODEL FOR PRODUCTION\n",
    "# =============================================================================\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "\n",
    "print(\"SAVING YOUR TRAINED LIGHTGBM MODEL...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Save as pickle\n",
    "with open('lightgbm_trained_model.pkl', 'wb') as f:\n",
    "    pickle.dump(lgb_model, f)\n",
    "print(\"✅ Saved: lightgbm_trained_model.pkl\")\n",
    "\n",
    "# 2. Save LightGBM native booster (FASTEST)\n",
    "booster = lgb_model.booster_\n",
    "booster.save_model('lightgbm_trained_model.txt')\n",
    "print(\"✅ Saved: lightgbm_trained_model.txt (native FAST)\")\n",
    "\n",
    "# 3. Model info\n",
    "model_info = {\n",
    "    'features': X_encoded.columns.tolist(),\n",
    "    'target': 'attribution',\n",
    "    'trained_on_rows': len(df),\n",
    "    'roc_auc': float(roc_auc),\n",
    "    'precision': float(precision),\n",
    "    'recall': float(recall)\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('lightgbm_model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "print(\"✅ Saved: lightgbm_model_info.json\")\n",
    "\n",
    "print(\"\\nPRODUCTION READY!\")\n",
    "print(\"Files created:\")\n",
    "print(\"  lightgbm_trained_model.pkl\")\n",
    "print(\"  lightgbm_trained_model.txt (native)\")\n",
    "print(\"  lightgbm_model_info.json\")\n",
    "print(f\"Model: ROC-AUC {roc_auc:.3f} on {len(df):,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae88cdb-1031-4784-80c2-81203d398ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
