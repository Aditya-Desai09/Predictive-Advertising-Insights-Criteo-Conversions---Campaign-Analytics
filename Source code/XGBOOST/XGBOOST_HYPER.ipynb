{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c0ee4b7-a145-4445-804f-bc93c00eb8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOOST COMPLETE DATASET HYPERPARAMETER OPTIMIZATION\n",
      "=================================================================\n",
      "CHALLENGE: Beat baseline ROC-AUC 0.950, Precision 13.7%, Recall 91.1%\n",
      "TARGET: ROC-AUC >0.955, Precision >18%, Recall >90%, F1 >0.30\n",
      "DATASET: Complete 16,468,027 impressions\n",
      "\n",
      "Loading COMPLETE Criteo dataset...\n",
      "Loaded 16,468,027 COMPLETE impressions\n",
      "   Attribution rate: 2.69%\n",
      "   Click rate: 36.1%\n",
      "   Unique campaigns: 675\n",
      "   Optimizing memory usage...\n",
      "Memory optimized dataset ready\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "XGBOOST COMPLETE DATASET HYPERPARAMETER OPTIMIZATION\n",
    "====================================================\n",
    "Beat baseline: ROC-AUC 0.950, Precision 13.7%, Recall 91.1%, F1 0.239\n",
    "Target: ROC-AUC >0.955, Precision >18%, Recall >90%, F1 >0.30\n",
    "\n",
    "\n",
    "COMPLETE DATASET: 16,468,027 impressions\n",
    "GOAL: Maximize attribution predictions with superior performance\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import time\n",
    "import json\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "print(\"XGBOOST COMPLETE DATASET HYPERPARAMETER OPTIMIZATION\")\n",
    "print(\"=\" * 65)\n",
    "print(\"CHALLENGE: Beat baseline ROC-AUC 0.950, Precision 13.7%, Recall 91.1%\")\n",
    "print(\"TARGET: ROC-AUC >0.955, Precision >18%, Recall >90%, F1 >0.30\")\n",
    "print(\"DATASET: Complete 16,468,027 impressions\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 1. COMPLETE DATASET LOADING\n",
    "# =============================================================================\n",
    "print(\"\\nLoading COMPLETE Criteo dataset...\")\n",
    "\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('E:\\\\PROJECT_F\\\\F\\\\criteo_production_ready_data.csv') \n",
    "    print(f\"Loaded {len(df):,} COMPLETE impressions\")\n",
    "    print(f\"   Attribution rate: {df['attribution'].mean():.2%}\")\n",
    "    print(f\"   Click rate: {df['click'].mean():.1%}\")\n",
    "    print(f\"   Unique campaigns: {df['campaign'].nunique():,}\")\n",
    "    \n",
    "    # Memory optimization\n",
    "    print(\"   Optimizing memory usage...\")\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'int64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "        elif df[col].dtype == 'float64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "    \n",
    "    print(f\"Memory optimized dataset ready\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading complete dataset: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb715390-17d8-41d6-a11d-dfdabdfaeafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Advanced Feature Engineering...\n",
      "   Base features: 12\n",
      "   Adding advanced engineered features...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2. ADVANCED FEATURE ENGINEERING\n",
    "# =============================================================================\n",
    "print(\"\\nAdvanced Feature Engineering...\")\n",
    "\n",
    "\n",
    "# Core features (same as baseline for fair comparison)\n",
    "features = [\n",
    "    'campaign', 'cost', 'cpo', 'click',\n",
    "    'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat8', 'cat9'\n",
    "]\n",
    "\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df['attribution'].copy()\n",
    "\n",
    "\n",
    "print(f\"   Base features: {len(features)}\")\n",
    "\n",
    "\n",
    "# Advanced engineered features\n",
    "print(\"   Adding advanced engineered features...\")\n",
    "\n",
    "\n",
    "# 1. Campaign performance (same as baseline)\n",
    "campaign_perf = df.groupby('campaign')['attribution'].mean()\n",
    "X['campaign_perf'] = X['campaign'].map(campaign_perf)\n",
    "\n",
    "\n",
    "# 2. Cost quartiles (same as baseline)\n",
    "X['cost_quartile'] = pd.qcut(X['cost'], q=4, labels=False, duplicates='drop')\n",
    "\n",
    "\n",
    "# 3. NEW: Click-Cost interaction (high-value feature)\n",
    "X['click_cost_interaction'] = X['click'] * X['cost']\n",
    "\n",
    "\n",
    "# 4. NEW: Campaign click rate\n",
    "campaign_click_rate = df.groupby('campaign')['click'].mean()\n",
    "X['campaign_click_rate'] = X['campaign'].map(campaign_click_rate)\n",
    "\n",
    "\n",
    "# 5. NEW: Cost efficiency ratio\n",
    "X['cost_efficiency'] = X['cost'] / (X['cpo'] + 1)  # +1 to avoid division by zero\n",
    "\n",
    "\n",
    "# 6. NEW: Category interaction features\n",
    "X['cat1_cat2_interaction'] = X['cat1'].astype(str) + '_' + X['cat2'].astype(str)\n",
    "X['cat3_cat4_interaction'] = X['cat3'].astype(str) + '_' + X['cat4'].astype(str)\n",
    "\n",
    "\n",
    "print(f\"Total features: {X.shape[1]} (12 base + 7 advanced engineered)\")\n",
    "\n",
    "\n",
    "# Encode categorical features\n",
    "print(\"   Encoding categorical features...\")\n",
    "categorical_features = [\n",
    "    'campaign', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat8', 'cat9',\n",
    "    'cat1_cat2_interaction', 'cat3_cat4_interaction'\n",
    "]\n",
    "\n",
    "\n",
    "label_encoders = {}\n",
    "for feature in categorical_features:\n",
    "    if feature in X.columns:\n",
    "        le = LabelEncoder()\n",
    "        X[feature] = le.fit_transform(X[feature].astype(str))\n",
    "        label_encoders[feature] = le\n",
    "\n",
    "\n",
    "print(f\"Encoded {len(categorical_features)} categorical features\")\n",
    "\n",
    "\n",
    "# Clean up memory\n",
    "del df\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3. STRATIFIED TRAIN-TEST SPLIT\n",
    "# =============================================================================\n",
    "print(f\"\\nCreating stratified train-test split...\")\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"   Training set: {len(X_train):,} samples ({y_train.mean():.2%} attribution)\")\n",
    "print(f\"   Test set: {len(X_test):,} samples ({y_test.mean():.2%} attribution)\")\n",
    "\n",
    "\n",
    "# Calculate precise class imbalance\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"   Class imbalance ratio: {scale_pos_weight:.1f}:1\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4. BASELINE REPRODUCTION\n",
    "# =============================================================================\n",
    "print(f\"\\nReproducing baseline performance...\")\n",
    "\n",
    "\n",
    "baseline_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,  # Same as baseline\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric='auc'\n",
    ")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "baseline_model.fit(X_train, y_train)\n",
    "baseline_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Baseline evaluation\n",
    "y_pred_baseline = baseline_model.predict(X_test)\n",
    "y_pred_proba_baseline = baseline_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "baseline_metrics = {\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_proba_baseline),\n",
    "    'precision': precision_score(y_test, y_pred_baseline),\n",
    "    'recall': recall_score(y_test, y_pred_baseline),\n",
    "    'f1_score': f1_score(y_test, y_pred_baseline),\n",
    "    'training_time': baseline_time\n",
    "}\n",
    "\n",
    "\n",
    "print(f\"Baseline Performance (to beat):\")\n",
    "print(f\"   ROC-AUC: {baseline_metrics['roc_auc']:.3f} (target: >0.955)\")\n",
    "print(f\"   Precision: {baseline_metrics['precision']:.1%} (target: >18%)\")\n",
    "print(f\"   Recall: {baseline_metrics['recall']:.1%} (target: >90%)\")\n",
    "print(f\"   F1-Score: {baseline_metrics['f1_score']:.3f} (target: >0.30)\")\n",
    "print(f\"   Training Time: {baseline_metrics['training_time']:.1f}s\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 5. ADVANCED HYPERPARAMETER OPTIMIZATION\n",
    "# =============================================================================\n",
    "print(f\"\\nADVANCED HYPERPARAMETER OPTIMIZATION\")\n",
    "print(\"=\" * 50)\n",
    "print(\"STRATEGY: Precision-focused optimization while maintaining recall\")\n",
    "\n",
    "\n",
    "# Expanded parameter grid for superior performance\n",
    "param_distributions = {\n",
    "    # Boosting parameters - more aggressive for better performance\n",
    "    'n_estimators': [300, 500, 800, 1000],  # More trees for complex patterns\n",
    "    'max_depth': [8, 10, 12, 15],           # Deeper trees for interactions\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15], # Include slower learning\n",
    "    \n",
    "    # Sampling parameters - critical for imbalanced data\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'colsample_bylevel': [0.7, 0.8, 0.9],\n",
    "    \n",
    "    # Regularization - prevent overfitting on large dataset\n",
    "    'reg_alpha': [0, 0.01, 0.1, 0.5, 1.0],\n",
    "    'reg_lambda': [0, 0.01, 0.1, 0.5, 1.0, 2.0],\n",
    "    \n",
    "    # Tree constraints\n",
    "    'min_child_weight': [1, 3, 5, 10],\n",
    "    'max_delta_step': [0, 1, 5],  # Can help with extreme imbalance\n",
    "    \n",
    "    # Class imbalance handling - fine-tuned\n",
    "    'scale_pos_weight': [\n",
    "        scale_pos_weight * 0.7,  # Less aggressive\n",
    "        scale_pos_weight * 0.8,\n",
    "        scale_pos_weight * 0.9,\n",
    "        scale_pos_weight,        # Calculated value\n",
    "        scale_pos_weight * 1.1,\n",
    "        scale_pos_weight * 1.2,\n",
    "        scale_pos_weight * 1.3   # More aggressive\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "total_combinations = np.prod([len(v) for v in param_distributions.values()])\n",
    "print(f\"Advanced search space: {total_combinations:,} combinations\")\n",
    "print(f\"   Testing 50 iterations with 3-fold cross-validation\")\n",
    "\n",
    "\n",
    "# Advanced XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    random_state=42,\n",
    "    n_jobs=1,\n",
    "    eval_metric='auc',\n",
    "    tree_method='hist',  # Faster for large datasets\n",
    "    grow_policy='lossguide'  # Better for complex patterns\n",
    ")\n",
    "\n",
    "\n",
    "# Cross-validation strategy\n",
    "cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# Custom scoring function that prioritizes precision while maintaining recall\n",
    "def custom_f1_scorer(y_true, y_pred):\n",
    "    \"\"\"Custom scorer that weights precision higher\"\"\"\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    # F-beta score with beta=0.5 (weights precision 2x more than recall)\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    f_beta = (1 + 0.5**2) * (precision * recall) / ((0.5**2 * precision) + recall)\n",
    "    return f_beta\n",
    "\n",
    "\n",
    "# Advanced randomized search\n",
    "print(\"Starting advanced hyperparameter optimization...\")\n",
    "print(\"   This will take 20-40 minutes for complete dataset...\")\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,  # More iterations for better results\n",
    "    cv=cv_strategy,\n",
    "    scoring='f1',  # Standard F1 for balanced optimization\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=2  # More verbose output\n",
    ")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "random_search.fit(X_train, y_train)\n",
    "optimization_time = time.time() - start_time\n",
    "\n",
    "\n",
    "print(f\"Advanced optimization completed in {optimization_time/60:.1f} minutes\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 6. OPTIMIZED MODEL EVALUATION\n",
    "# =============================================================================\n",
    "print(f\"\\nOPTIMIZED MODEL RESULTS...\")\n",
    "\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "\n",
    "print(f\"Best Parameters Found:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"   • {param}: {value}\")\n",
    "\n",
    "\n",
    "# Evaluate optimized model\n",
    "y_pred_optimized = best_model.predict(X_test)\n",
    "y_pred_proba_optimized = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "optimized_metrics = {\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_proba_optimized),\n",
    "    'precision': precision_score(y_test, y_pred_optimized),\n",
    "    'recall': recall_score(y_test, y_pred_optimized),\n",
    "    'f1_score': f1_score(y_test, y_pred_optimized),\n",
    "    'cv_score': random_search.best_score_\n",
    "}\n",
    "\n",
    "\n",
    "print(f\"\\nOPTIMIZED PERFORMANCE:\")\n",
    "print(f\"   ROC-AUC: {optimized_metrics['roc_auc']:.3f}\")\n",
    "print(f\"   CV F1-Score: {optimized_metrics['cv_score']:.3f}\")\n",
    "print(f\"   Precision: {optimized_metrics['precision']:.1%}\")\n",
    "print(f\"   Recall: {optimized_metrics['recall']:.1%}\")\n",
    "print(f\"   F1-Score: {optimized_metrics['f1_score']:.3f}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 7. PERFORMANCE COMPARISON VS BASELINE\n",
    "# =============================================================================\n",
    "print(f\"\\nPERFORMANCE COMPARISON VS BASELINE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Metric':<12} {'Baseline':<12} {'Optimized':<12} {'Improvement':<12} {'Target Met'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# Define targets\n",
    "targets = {\n",
    "    'roc_auc': 0.955,\n",
    "    'precision': 0.18,\n",
    "    'recall': 0.90,\n",
    "    'f1_score': 0.30\n",
    "}\n",
    "\n",
    "\n",
    "improvements = {}\n",
    "targets_met = {}\n",
    "\n",
    "\n",
    "for metric in ['roc_auc', 'precision', 'recall', 'f1_score']:\n",
    "    baseline_val = baseline_metrics[metric]\n",
    "    optimized_val = optimized_metrics[metric]\n",
    "    improvement = ((optimized_val - baseline_val) / baseline_val) * 100\n",
    "    improvements[metric] = improvement\n",
    "    \n",
    "    target_met = \"YES\" if optimized_val >= targets[metric] else \"NO\"\n",
    "    targets_met[metric] = optimized_val >= targets[metric]\n",
    "    \n",
    "    print(f\"{metric.upper():<12} {baseline_val:<12.3f} {optimized_val:<12.3f} {improvement:+8.1f}% {target_met}\")\n",
    "\n",
    "\n",
    "# Overall success assessment\n",
    "targets_achieved = sum(targets_met.values())\n",
    "print(f\"\\nTARGETS ACHIEVED: {targets_achieved}/4\")\n",
    "\n",
    "\n",
    "if targets_achieved >= 3:\n",
    "    print(\"OPTIMIZATION SUCCESSFUL! Significant improvement achieved.\")\n",
    "elif targets_achieved >= 2:\n",
    "    print(\"OPTIMIZATION GOOD! Moderate improvement achieved.\")\n",
    "else:\n",
    "    print(\"OPTIMIZATION PARTIAL! Some improvement but targets not fully met.\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 8. DETAILED CONFUSION MATRIX ANALYSIS\n",
    "# =============================================================================\n",
    "print(f\"\\nDETAILED CONFUSION MATRIX ANALYSIS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "\n",
    "cm_baseline = confusion_matrix(y_test, y_pred_baseline)\n",
    "cm_optimized = confusion_matrix(y_test, y_pred_optimized)\n",
    "\n",
    "\n",
    "print(f\"BASELINE CONFUSION MATRIX:\")\n",
    "print(f\"   True Negatives:  {cm_baseline[0,0]:,}\")\n",
    "print(f\"   False Positives: {cm_baseline[0,1]:,}\")\n",
    "print(f\"   False Negatives: {cm_baseline[1,0]:,}\")\n",
    "print(f\"   True Positives:  {cm_baseline[1,1]:,}\")\n",
    "\n",
    "\n",
    "print(f\"\\nOPTIMIZED CONFUSION MATRIX:\")\n",
    "print(f\"   True Negatives:  {cm_optimized[0,0]:,}\")\n",
    "print(f\"   False Positives: {cm_optimized[0,1]:,}\")\n",
    "print(f\"   False Negatives: {cm_optimized[1,0]:,}\")\n",
    "print(f\"   True Positives:  {cm_optimized[1,1]:,}\")\n",
    "\n",
    "\n",
    "# Attribution improvement analysis\n",
    "tp_improvement = cm_optimized[1,1] - cm_baseline[1,1]\n",
    "fp_change = cm_optimized[0,1] - cm_baseline[0,1]\n",
    "\n",
    "\n",
    "print(f\"\\nATTRIBUTION PREDICTIONS IMPROVEMENT:\")\n",
    "print(f\"   Additional True Positives: {tp_improvement:,}\")\n",
    "print(f\"   Change in False Positives: {fp_change:,}\")\n",
    "\n",
    "\n",
    "if cm_baseline[1,1] > 0:\n",
    "    tp_percent_improvement = (tp_improvement / cm_baseline[1,1]) * 100\n",
    "    print(f\"   True Positive improvement: {tp_percent_improvement:+.1f}%\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 9. ADVANCED FEATURE IMPORTANCE\n",
    "# =============================================================================\n",
    "print(f\"\\nADVANCED FEATURE IMPORTANCE ANALYSIS:\")\n",
    "\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "\n",
    "print(f\"\\nTop 15 Most Important Features:\")\n",
    "for i, (_, row) in enumerate(feature_importance.head(15).iterrows(), 1):\n",
    "    print(f\"   {i:2d}. {row['feature']:<25} {row['importance']:>8.3f}\")\n",
    "\n",
    "\n",
    "# Compare with baseline top features\n",
    "print(f\"\\nNEW ENGINEERED FEATURES IMPACT:\")\n",
    "engineered_features = [\n",
    "    'click_cost_interaction', 'campaign_click_rate', 'cost_efficiency',\n",
    "    'cat1_cat2_interaction', 'cat3_cat4_interaction'\n",
    "]\n",
    "\n",
    "\n",
    "for feature in engineered_features:\n",
    "    if feature in feature_importance['feature'].values:\n",
    "        importance = feature_importance[feature_importance['feature'] == feature]['importance'].iloc[0]\n",
    "        rank = feature_importance[feature_importance['feature'] == feature].index[0] + 1\n",
    "        print(f\"   {feature:<25} Rank: {rank:2d}, Importance: {importance:.3f}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 10. BUSINESS IMPACT ANALYSIS\n",
    "# =============================================================================\n",
    "print(f\"\\nBUSINESS IMPACT ANALYSIS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "\n",
    "# Calculate business metrics\n",
    "total_test_impressions = len(y_test)\n",
    "baseline_attributions = cm_baseline[1,1]\n",
    "optimized_attributions = cm_optimized[1,1]\n",
    "additional_attributions = optimized_attributions - baseline_attributions\n",
    "\n",
    "\n",
    "# Revenue impact (assuming $50 per attribution)\n",
    "avg_revenue_per_attribution = 50\n",
    "additional_revenue = additional_attributions * avg_revenue_per_attribution\n",
    "\n",
    "\n",
    "# Cost impact (false positives cost money)\n",
    "baseline_fp_cost = cm_baseline[0,1] * 5  # $5 per false positive\n",
    "optimized_fp_cost = cm_optimized[0,1] * 5\n",
    "cost_change = optimized_fp_cost - baseline_fp_cost\n",
    "\n",
    "\n",
    "net_revenue_impact = additional_revenue - cost_change\n",
    "\n",
    "\n",
    "print(f\"Business Impact Metrics:\")\n",
    "print(f\"   Test impressions: {total_test_impressions:,}\")\n",
    "print(f\"   Baseline attributions: {baseline_attributions:,}\")\n",
    "print(f\"   Optimized attributions: {optimized_attributions:,}\")\n",
    "print(f\"   Additional attributions: {additional_attributions:,}\")\n",
    "print(f\"   Additional revenue: ${additional_revenue:,}\")\n",
    "print(f\"   Cost change (FP): ${cost_change:,}\")\n",
    "print(f\"   Net revenue impact: ${net_revenue_impact:,}\")\n",
    "\n",
    "\n",
    "if baseline_attributions > 0:\n",
    "    attribution_lift = (additional_attributions / baseline_attributions) * 100\n",
    "    print(f\"   Attribution lift: {attribution_lift:+.1f}%\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 11. SAVE COMPREHENSIVE RESULTS\n",
    "# =============================================================================\n",
    "print(f\"\\nSaving comprehensive optimization results...\")\n",
    "\n",
    "\n",
    "# Complete results dictionary\n",
    "results = {\n",
    "    'optimization_info': {\n",
    "        'dataset_size': len(X),\n",
    "        'complete_dataset': True,\n",
    "        'attribution_rate': y.mean(),\n",
    "        'optimization_time_minutes': optimization_time / 60,\n",
    "        'search_iterations': 50,\n",
    "        'cv_folds': 3,\n",
    "        'advanced_features': True\n",
    "    },\n",
    "    'targets': targets,\n",
    "    'targets_achieved': {k: bool(v) for k, v in targets_met.items()},\n",
    "    'targets_met_count': targets_achieved,\n",
    "    'best_parameters': best_params,\n",
    "    'baseline_performance': baseline_metrics,\n",
    "    'optimized_performance': optimized_metrics,\n",
    "    'improvements': improvements,\n",
    "    'feature_importance': feature_importance.to_dict('records'),\n",
    "    'engineered_features_impact': {\n",
    "        feature: {\n",
    "            'importance': float(feature_importance[feature_importance['feature'] == feature]['importance'].iloc[0])\n",
    "            if feature in feature_importance['feature'].values else 0,\n",
    "            'rank': int(feature_importance[feature_importance['feature'] == feature].index[0] + 1)\n",
    "            if feature in feature_importance['feature'].values else len(feature_importance)\n",
    "        }\n",
    "        for feature in engineered_features\n",
    "    },\n",
    "    'business_impact': {\n",
    "        'additional_attributions': int(additional_attributions),\n",
    "        'attribution_lift_percent': float(attribution_lift) if baseline_attributions > 0 else 0,\n",
    "        'additional_revenue': float(additional_revenue),\n",
    "        'cost_change': float(cost_change),\n",
    "        'net_revenue_impact': float(net_revenue_impact)\n",
    "    },\n",
    "    'confusion_matrices': {\n",
    "        'baseline': cm_baseline.tolist(),\n",
    "        'optimized': cm_optimized.tolist()\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Save results\n",
    "with open('xgboost_complete_optimization_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2, default=str)\n",
    "\n",
    "\n",
    "feature_importance.to_csv('xgboost_complete_feature_importance.csv', index=False)\n",
    "\n",
    "\n",
    "# Save model parameters for production\n",
    "production_config = {\n",
    "    'model_class': 'XGBClassifier',\n",
    "    'parameters': best_params,\n",
    "    'performance': optimized_metrics,\n",
    "    'feature_names': list(X.columns),\n",
    "    'label_encoders': {k: list(v.classes_) for k, v in label_encoders.items()}\n",
    "}\n",
    "\n",
    "\n",
    "with open('xgboost_production_config.json', 'w') as f:\n",
    "    json.dump(production_config, f, indent=2, default=str)\n",
    "\n",
    "\n",
    "print(\"Comprehensive results saved:\")\n",
    "print(\"   • xgboost_complete_optimization_results.json\")\n",
    "print(\"   • xgboost_complete_feature_importance.csv\")\n",
    "print(\"   • xgboost_production_config.json\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 12. FINAL PRODUCTION RECOMMENDATIONS\n",
    "# =============================================================================\n",
    "print(f\"\\nFINAL PRODUCTION RECOMMENDATIONS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "\n",
    "if targets_achieved >= 3:\n",
    "    print(\"DEPLOY OPTIMIZED MODEL IMMEDIATELY\")\n",
    "    print(f\"   • Achieved {targets_achieved}/4 performance targets\")\n",
    "    print(f\"   • ROC-AUC: {optimized_metrics['roc_auc']:.3f} (vs baseline {baseline_metrics['roc_auc']:.3f})\")\n",
    "    print(f\"   • Precision: {optimized_metrics['precision']:.1%} (vs baseline {baseline_metrics['precision']:.1%})\")\n",
    "    print(f\"   • Additional revenue: ${additional_revenue:,}\")\n",
    "elif targets_achieved >= 2:\n",
    "    print(\"DEPLOY WITH MONITORING\")\n",
    "    print(f\"   • Achieved {targets_achieved}/4 performance targets\")\n",
    "    print(f\"   • Significant improvement over baseline\")\n",
    "    print(f\"   • Monitor performance closely in production\")\n",
    "else:\n",
    "    print(\"FURTHER OPTIMIZATION RECOMMENDED\")\n",
    "    print(f\"   • Only achieved {targets_achieved}/4 performance targets\")\n",
    "    print(f\"   • Consider ensemble methods or deep learning\")\n",
    "\n",
    "\n",
    "print(f\"\\nProduction-Ready Configuration:\")\n",
    "print(\"```python\")\n",
    "print(\"xgb.XGBClassifier(\")\n",
    "for param, value in best_params.items():\n",
    "    if isinstance(value, str):\n",
    "        print(f\"    {param}='{value}',\")\n",
    "    else:\n",
    "        print(f\"    {param}={value},\")\n",
    "print(\"    random_state=42,\")\n",
    "print(\"    n_jobs=-1,\")\n",
    "print(\"    eval_metric='auc',\")\n",
    "print(\"    tree_method='hist',\")\n",
    "print(\"    grow_policy='lossguide'\")\n",
    "print(\")\")\n",
    "print(\"```\")\n",
    "\n",
    "\n",
    "print(f\"\\nExpected Production Performance:\")\n",
    "print(f\"   • ROC-AUC: {optimized_metrics['roc_auc']:.3f}\")\n",
    "print(f\"   • Precision: {optimized_metrics['precision']:.1%}\")\n",
    "print(f\"   • Recall: {optimized_metrics['recall']:.1%}\")\n",
    "print(f\"   • F1-Score: {optimized_metrics['f1_score']:.3f}\")\n",
    "print(f\"   • Training time: ~{optimization_time/60:.0f} minutes for full dataset\")\n",
    "\n",
    "\n",
    "print(f\"\\nKey Success Factors:\")\n",
    "print(f\"   • Advanced feature engineering with {len(engineered_features)} new features\")\n",
    "print(f\"   • Optimized for complete {len(X):,} sample dataset\")\n",
    "print(f\"   • Fine-tuned class imbalance handling\")\n",
    "print(f\"   • Production-ready configuration with robust parameters\")\n",
    "\n",
    "\n",
    "print(f\"\\nXGBOOST COMPLETE DATASET OPTIMIZATION COMPLETED!\")\n",
    "print(f\"Successfully optimized for maximum Criteo attribution predictions!\")\n",
    "print(f\"Ready for production deployment on 16.4M+ impression dataset!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f19c69a-8e58-4abe-a702-096104d728ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SAVE MODEL TO PICKLE FILE\n",
    "# =============================================================================\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\nSAVING TRAINED MODEL...\")\n",
    "\n",
    "# Model metadata\n",
    "model_info = {\n",
    "    'model_name': 'XGBoost_Criteo_Attribution_Baseline',\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'dataset_size': len(X_train),\n",
    "    'features': list(X.columns),\n",
    "    'performance': baseline_metrics,\n",
    "    'parameters': baseline_model.get_params(),\n",
    "    'label_encoders': {k: list(v.classes_) for k, v in label_encoders.items()}\n",
    "}\n",
    "\n",
    "# Save the model\n",
    "model_filename = 'criteo_attribution_xgboost_model.pkl'\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': baseline_model,\n",
    "        'label_encoders': label_encoders,\n",
    "        'feature_names': list(X.columns),\n",
    "        'metadata': model_info\n",
    "    }, f)\n",
    "\n",
    "print(f\"Model saved successfully: {model_filename}\")\n",
    "print(f\"   Model type: XGBoost Classifier\")\n",
    "print(f\"   Features: {len(X.columns)}\")\n",
    "print(f\"   ROC-AUC: {baseline_metrics['roc_auc']:.3f}\")\n",
    "print(f\"   Precision: {baseline_metrics['precision']:.1%}\")\n",
    "print(f\"   Recall: {baseline_metrics['recall']:.1%}\")\n",
    "\n",
    "# Also save metadata separately for easy reference\n",
    "import json\n",
    "with open('criteo_model_metadata.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nMetadata saved: criteo_model_metadata.json\")\n",
    "\n",
    "# Optional: Test loading the model\n",
    "print(\"\\nTesting model loading...\")\n",
    "with open(model_filename, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "    loaded_model = loaded_data['model']\n",
    "    \n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"Model ready for production deployment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea00109-b1cc-48ce-97ea-8817a9820bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load saved model for predictions\n",
    "# import pickle\n",
    "\n",
    "# with open('criteo_attribution_xgboost_model.pkl', 'rb') as f:\n",
    "#     saved_data = pickle.load(f)\n",
    "    \n",
    "# model = saved_data['model']\n",
    "# label_encoders = saved_data['label_encoders']\n",
    "# feature_names = saved_data['feature_names']\n",
    "# metadata = saved_data['metadata']\n",
    "\n",
    "# # Make predictions\n",
    "# y_predictions = model.predict(X_new)\n",
    "# y_probabilities = model.predict_proba(X_new)[:, 1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
