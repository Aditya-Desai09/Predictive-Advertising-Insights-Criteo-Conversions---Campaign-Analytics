{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d921aa3d-96e4-4b55-aacb-8f3947f4dfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRITEO ATTRIBUTION MODELING - XGBOOST\n",
      "=================================================================\n",
      "\n",
      "Loading COMPLETE data...\n",
      "Loaded 16,468,027 impressions\n",
      "\n",
      "Dataset Overview:\n",
      "  Total impressions: 16,468,027\n",
      "  Attribution rate: 2.7%\n",
      "  Challenge: Highly imbalanced dataset\n",
      "\n",
      "Feature Engineering...\n",
      "  Selected 12 features\n",
      "  Excluded cat7: 57,196 unique values (too high)\n",
      "  Added campaign performance and cost quartiles\n",
      "  Total features: 14\n",
      "  Data split: (13174421, 14) train, (3293606, 14) test\n",
      "\n",
      "XGBOOST (State-of-the-art Gradient Boosting)\n",
      "-----------------------------------------------------------------\n",
      "Training XGBoost...\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "CRITEO ATTRIBUTION MODELING - XGBOOST ONLY\n",
    "==========================================\n",
    "\n",
    "XGBoost: State-of-the-art gradient boosting\n",
    "Competition winner, excellent for structured data, production favorite.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"CRITEO ATTRIBUTION MODELING - XGBOOST\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# Load COMPLETE dataset (ALL ROWS)\n",
    "print(\"\\nLoading COMPLETE data...\")\n",
    "try:\n",
    "    df = pd.read_csv('pcb_dataset_final.csv')  # ALL ROWS\n",
    "    print(f\"Loaded {len(df):,} impressions\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Basic info\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"  Total impressions: {len(df):,}\")\n",
    "print(f\"  Attribution rate: {df['attribution'].mean():.1%}\")\n",
    "print(f\"  Challenge: Highly imbalanced dataset\")\n",
    "\n",
    "# Feature selection (production-ready)\n",
    "print(f\"\\nFeature Engineering...\")\n",
    "features = [\n",
    "    'campaign', 'cost', 'cpo', 'click',\n",
    "    'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat8', 'cat9'  # Exclude cat7\n",
    "]\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df['attribution'].copy()\n",
    "\n",
    "print(f\"  Selected {len(features)} features\")\n",
    "print(f\"  Excluded cat7: {df['cat7'].nunique():,} unique values (too high)\")\n",
    "\n",
    "# Simple feature engineering\n",
    "campaign_perf = df.groupby('campaign')['attribution'].mean()\n",
    "X['campaign_perf'] = X['campaign'].map(campaign_perf).fillna(df['attribution'].mean())\n",
    "X['cost_quartile'] = pd.qcut(X['cost'], q=4, labels=[1,2,3,4]).astype(int)\n",
    "\n",
    "print(f\"  Added campaign performance and cost quartiles\")\n",
    "print(f\"  Total features: {X.shape[1]}\")\n",
    "\n",
    "# Prepare data - encode categoricals for XGBoost\n",
    "categorical_cols = ['campaign'] + [col for col in X.columns if col.startswith('cat')]\n",
    "X_encoded = X.copy()\n",
    "for col in categorical_cols:\n",
    "    if col in X_encoded.columns:\n",
    "        le = LabelEncoder()\n",
    "        X_encoded[col] = le.fit_transform(X_encoded[col].astype(str))\n",
    "\n",
    "# Split data (stratified for balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"  Data split: {X_train.shape} train, {X_test.shape} test\")\n",
    "\n",
    "# XGBOOST (State-of-the-art Gradient Boosting)\n",
    "print(f\"\\nXGBOOST (State-of-the-art Gradient Boosting)\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,  # Balanced for full dataset\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    verbosity=0,\n",
    "    scale_pos_weight=(y==0).sum()/(y.sum()+1),  # Handle imbalance\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training XGBoost...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Train on encoded data\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "y_prob = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Calculate metrics\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "# Confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Feature importance (top 10)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_encoded.columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(10)\n",
    "\n",
    "# Results\n",
    "print(f\"\\nRESULTS - XGBOOST (COMPLETE DATASET)\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"ROC-AUC:        {roc_auc:.3f}\")\n",
    "print(f\"Precision:      {precision:.3f} ({precision:.1%})\")\n",
    "print(f\"Recall:         {recall:.3f} ({recall:.1%})\")\n",
    "print(f\"F1-Score:       {f1:.3f}\")\n",
    "print(f\"Training Time:  {training_time:.1f} seconds\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"True Positives:  {tp:,}\")\n",
    "print(f\"False Positives: {fp:,}\")\n",
    "print(f\"True Negatives:  {tn:,}\")\n",
    "print(f\"False Negatives: {fn:,}\")\n",
    "print(f\"Correct:         {tp + tn:,} ({(tp + tn) / (tp + tn + fp + fn):.1%})\")\n",
    "\n",
    "print(f\"\\nTOP 10 FEATURE IMPORTANCE:\")\n",
    "print(\"-\" * 35)\n",
    "for _, row in feature_importance.iterrows():\n",
    "    print(f\"{row['feature']:<20} {row['importance']:.3f}\")\n",
    "\n",
    "print(f\"\\nWHY XGBOOST IS INDUSTRY STANDARD:\")\n",
    "print(f\"  Competition winner (Kaggle champion)\")\n",
    "print(f\"  Gradient boosting with regularization\")\n",
    "print(f\"  Handles imbalanced data (scale_pos_weight)\")\n",
    "print(f\"  Parallel training (n_jobs=-1)\")\n",
    "print(f\"  Built-in early stopping and validation\")\n",
    "\n",
    "# Save results\n",
    "results_df = pd.DataFrame([{\n",
    "    'Model': 'XGBoost (Complete Dataset)',\n",
    "    'ROC-AUC': roc_auc,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'Training_Time': training_time,\n",
    "    'TP': tp, 'FP': fp, 'TN': tn, 'FN': fn,\n",
    "    'Dataset_Size': len(df)\n",
    "}])\n",
    "results_df.to_csv('xgboost_complete_results.csv', index=False)\n",
    "\n",
    "feature_importance.to_csv('xgboost_feature_importance.csv', index=False)\n",
    "\n",
    "# Project summary\n",
    "summary = {\n",
    "    'project_title': 'Criteo Attribution Modeling - XGBoost (Complete Dataset)',\n",
    "    'model': 'XGBoost',\n",
    "    'dataset': {\n",
    "        'size': f\"{len(df):,} impressions\",\n",
    "        'attribution_rate': f\"{y.mean():.1%}\",\n",
    "        'features': X.shape[1]\n",
    "    },\n",
    "    'performance': {\n",
    "        'roc_auc': f\"{roc_auc:.3f}\",\n",
    "        'precision': f\"{precision:.1%}\",\n",
    "        'recall': f\"{recall:.1%}\",\n",
    "        'training_time': f\"{training_time:.1f}s\"\n",
    "    },\n",
    "    'top_features': feature_importance.head(5).to_dict('records'),\n",
    "    'key_achievements': [\n",
    "        f\"Trained on COMPLETE dataset ({len(df):,} rows)\",\n",
    "        f\"ROC-AUC: {roc_auc:.3f}\",\n",
    "        f\"Fast execution: {training_time:.1f} seconds (parallelized)\",\n",
    "        \"Feature importance analysis included\",\n",
    "        \"State-of-the-art gradient boosting\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('xgboost_complete_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nFiles saved:\")\n",
    "print(f\"  xgboost_complete_results.csv\")\n",
    "print(f\"  xgboost_feature_importance.csv\")\n",
    "print(f\"  xgboost_complete_summary.json\")\n",
    "\n",
    "print(f\"\\nXGBOOST COMPLETE!\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"Dataset: {len(df):,} COMPLETE impressions\")\n",
    "print(f\"ROC-AUC: {roc_auc:.3f}\")\n",
    "print(f\"Precision: {precision:.1%}\")\n",
    "print(f\"Recall: {recall:.1%}\")\n",
    "print(f\"Training Time: {training_time:.1f}s\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "print(f\"\\nFOR YOUR PROJECT:\")\n",
    "print(f\"  Problem: Predict advertising attribution success\")\n",
    "print(f\"  Data: {len(df):,} COMPLETE Criteo impressions ({y.mean():.1%} success rate)\")\n",
    "print(f\"  Model: XGBoost (state-of-the-art gradient boosting)\")\n",
    "print(f\"  ROC-AUC: {roc_auc:.3f}\")\n",
    "print(f\"  Value: Competition-winning performance, production scalable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af8d43-e83c-4f65-9dc9-2bb63ad8ff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SAVE TRAINED XGBOOST MODEL FOR PRODUCTION\n",
    "# =============================================================================\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "print(\"SAVING YOUR TRAINED XGBOOST MODEL...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Save the trained model (xgb_model from previous cell)\n",
    "with open('xgboost_trained_model.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb_model, f)\n",
    "print(\"âœ… Saved: xgboost_trained_model.pkl\")\n",
    "\n",
    "# 2. Alternative: XGBoost native format (faster)\n",
    "xgb_model.save_model('xgboost_trained_model.json')\n",
    "print(\"âœ… Saved: xgboost_trained_model.json (native FAST)\")\n",
    "\n",
    "# 3. Save feature names and preprocessing info\n",
    "model_info = {\n",
    "    'features': X_encoded.columns.tolist(),\n",
    "    'target': 'attribution',\n",
    "    'trained_on_rows': len(df),\n",
    "    'roc_auc': roc_auc,\n",
    "    'precision': float(precision),\n",
    "    'recall': float(recall)\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('xgboost_model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "print(\"âœ… Saved: xgboost_model_info.json\")\n",
    "\n",
    "# 4. PRODUCTION PREDICTION FUNCTION (Ready to copy!)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PRODUCTION PREDICTION CODE (Copy this for deployment):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pred_code = '''\n",
    "# === PRODUCTION USE ===\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load model\n",
    "model = pickle.load(open(\"xgboost_trained_model.pkl\", \"rb\"))\n",
    "# OR FASTER: model = xgb.XGBClassifier(); model.load_model(\"xgboost_trained_model.json\")\n",
    "\n",
    "# Load feature info\n",
    "import json\n",
    "with open(\"xgboost_model_info.json\") as f:\n",
    "    info = json.load(f)\n",
    "\n",
    "def predict_new_data(new_df):\n",
    "    \"\"\"Predict attribution for NEW impressions\"\"\"\n",
    "    # Apply SAME preprocessing as training\n",
    "    X_new = new_df[info[\"features\"]].copy()\n",
    "    \n",
    "    # Recreate engineered features (campaign_perf, cost_quartile)\n",
    "    campaign_perf = new_df.groupby(\"campaign\")[\"attribution\"].mean()\n",
    "    X_new[\"campaign_perf\"] = new_df[\"campaign\"].map(campaign_perf).fillna(0.032)\n",
    "    X_new[\"cost_quartile\"] = pd.qcut(new_df[\"cost\"], q=4, labels=[1,2,3,4]).astype(int)\n",
    "    \n",
    "    # Encode categoricals (you need to recreate encoders or use same method)\n",
    "    for col in [\"campaign\", \"cat1\", \"cat2\", \"cat3\", \"cat4\", \"cat5\", \"cat6\", \"cat8\", \"cat9\"]:\n",
    "        if col in X_new.columns:\n",
    "            le = pd.Series(X_new[col].astype(str)).astype('category').cat.codes\n",
    "            X_new[col] = le\n",
    "    \n",
    "    # Predict!\n",
    "    probs = model.predict_proba(X_new)[:, 1]\n",
    "    return probs\n",
    "\n",
    "# Example:\n",
    "# new_ads = pd.read_csv(\"new_campaign_data.csv\")\n",
    "# predictions = predict_new_data(new_ads)\n",
    "# print(f\"Avg attribution probability: {predictions.mean():.3f}\")\n",
    "'''\n",
    "\n",
    "print(pred_code)\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nðŸŽ‰ MODEL SAVED SUCCESSFULLY!\")\n",
    "print(f\"Files created:\")\n",
    "print(f\"  xgboost_trained_model.pkl\")\n",
    "print(f\"  xgboost_trained_model.json (native)\")\n",
    "print(f\"  xgboost_model_info.json\")\n",
    "print(f\"Model trained on: {len(df):,} rows | ROC-AUC: {roc_auc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cba6b33-14e3-48b0-9590-a538361bb956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
