{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c0ee4b7-a145-4445-804f-bc93c00eb8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOOST COMPLETE DATASET HYPERPARAMETER OPTIMIZATION\n",
      "=================================================================\n",
      "CHALLENGE: Beat baseline ROC-AUC 0.950, Precision 13.7%, Recall 91.1%\n",
      "TARGET: ROC-AUC >0.955, Precision >18%, Recall >90%, F1 >0.30\n",
      "DATASET: Complete 16,468,027 impressions\n",
      "\n",
      "Loading COMPLETE Criteo dataset...\n",
      "Loaded 16,468,027 COMPLETE impressions\n",
      "   Attribution rate: 2.69%\n",
      "   Click rate: 36.1%\n",
      "   Unique campaigns: 675\n",
      "   Optimizing memory usage...\n",
      "Memory optimized dataset ready\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "XGBOOST COMPLETE DATASET HYPERPARAMETER OPTIMIZATION\n",
    "====================================================\n",
    "Beat baseline: ROC-AUC 0.950, Precision 13.7%, Recall 91.1%, F1 0.239\n",
    "Target: ROC-AUC >0.955, Precision >18%, Recall >90%, F1 >0.30\n",
    "\n",
    "\n",
    "COMPLETE DATASET: 16,468,027 impressions\n",
    "GOAL: Maximize attribution predictions with superior performance\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import time\n",
    "import json\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "print(\"XGBOOST COMPLETE DATASET HYPERPARAMETER OPTIMIZATION\")\n",
    "print(\"=\" * 65)\n",
    "print(\"CHALLENGE: Beat baseline ROC-AUC 0.950, Precision 13.7%, Recall 91.1%\")\n",
    "print(\"TARGET: ROC-AUC >0.955, Precision >18%, Recall >90%, F1 >0.30\")\n",
    "print(\"DATASET: Complete 16,468,027 impressions\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 1. COMPLETE DATASET LOADING\n",
    "# =============================================================================\n",
    "print(\"\\nLoading COMPLETE Criteo dataset...\")\n",
    "\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('E:\\\\PROJECT_F\\\\F\\\\criteo_production_ready_data.csv') \n",
    "    print(f\"Loaded {len(df):,} COMPLETE impressions\")\n",
    "    print(f\"   Attribution rate: {df['attribution'].mean():.2%}\")\n",
    "    print(f\"   Click rate: {df['click'].mean():.1%}\")\n",
    "    print(f\"   Unique campaigns: {df['campaign'].nunique():,}\")\n",
    "    \n",
    "    # Memory optimization\n",
    "    print(\"   Optimizing memory usage...\")\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'int64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "        elif df[col].dtype == 'float64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "    \n",
    "    print(f\"Memory optimized dataset ready\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading complete dataset: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb715390-17d8-41d6-a11d-dfdabdfaeafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Advanced Feature Engineering...\n",
      "   Base features: 12\n",
      "   Adding advanced engineered features...\n",
      "Total features: 19 (12 base + 7 advanced engineered)\n",
      "   Encoding categorical features...\n",
      "Encoded 11 categorical features\n",
      "\n",
      "Creating stratified train-test split...\n",
      "   Training set: 13,174,421 samples (2.69% attribution)\n",
      "   Test set: 3,293,606 samples (2.69% attribution)\n",
      "   Class imbalance ratio: 36.2:1\n",
      "\n",
      "Reproducing baseline performance...\n",
      "Baseline Performance (to beat):\n",
      "   ROC-AUC: 0.951 (target: >0.955)\n",
      "   Precision: 13.9% (target: >18%)\n",
      "   Recall: 91.3% (target: >90%)\n",
      "   F1-Score: 0.241 (target: >0.30)\n",
      "   Training Time: 27.4s\n",
      "\n",
      "ADVANCED HYPERPARAMETER OPTIMIZATION\n",
      "==================================================\n",
      "STRATEGY: Precision-focused optimization while maintaining recall\n",
      "Advanced search space: 4,354,560 combinations\n",
      "   Testing 50 iterations with 3-fold cross-validation\n",
      "Starting advanced hyperparameter optimization...\n",
      "   This will take 20-40 minutes for complete dataset...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTerminatedWorkerError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 231\u001b[39m\n\u001b[32m    218\u001b[39m random_search = RandomizedSearchCV(\n\u001b[32m    219\u001b[39m     estimator=xgb_model,\n\u001b[32m    220\u001b[39m     param_distributions=param_distributions,\n\u001b[32m   (...)\u001b[39m\u001b[32m    226\u001b[39m     verbose=\u001b[32m2\u001b[39m  \u001b[38;5;66;03m# More verbose output\u001b[39;00m\n\u001b[32m    227\u001b[39m )\n\u001b[32m    230\u001b[39m start_time = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m \u001b[43mrandom_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m optimization_time = time.time() - start_time\n\u001b[32m    235\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAdvanced optimization completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimization_time/\u001b[32m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m minutes\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1053\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1047\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1048\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1049\u001b[39m     )\n\u001b[32m   1051\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1056\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1057\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:2002\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   2000\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   2001\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2002\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2004\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   2005\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2006\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:999\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    991\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    992\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    993\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    994\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    995\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    996\u001b[39m         )\n\u001b[32m    997\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m999\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1021\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1022\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:91\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     79\u001b[39m warning_filters = (\n\u001b[32m     80\u001b[39m     filters_func() \u001b[38;5;28;01mif\u001b[39;00m filters_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m warnings.filters\n\u001b[32m     81\u001b[39m )\n\u001b[32m     83\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     84\u001b[39m     (\n\u001b[32m     85\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     90\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1748\u001b[39m \n\u001b[32m   1749\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1750\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1751\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1752\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1754\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1755\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1757\u001b[39m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1785\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1786\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1787\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1789\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    739\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    741\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    742\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    743\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    744\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    762\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    764\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mTerminatedWorkerError\u001b[39m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2. ADVANCED FEATURE ENGINEERING\n",
    "# =============================================================================\n",
    "print(\"\\nAdvanced Feature Engineering...\")\n",
    "\n",
    "\n",
    "# Core features (same as baseline for fair comparison)\n",
    "features = [\n",
    "    'campaign', 'cost', 'cpo', 'click',\n",
    "    'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat8', 'cat9'\n",
    "]\n",
    "\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df['attribution'].copy()\n",
    "\n",
    "\n",
    "print(f\"   Base features: {len(features)}\")\n",
    "\n",
    "\n",
    "# Advanced engineered features\n",
    "print(\"   Adding advanced engineered features...\")\n",
    "\n",
    "\n",
    "# 1. Campaign performance (same as baseline)\n",
    "campaign_perf = df.groupby('campaign')['attribution'].mean()\n",
    "X['campaign_perf'] = X['campaign'].map(campaign_perf)\n",
    "\n",
    "\n",
    "# 2. Cost quartiles (same as baseline)\n",
    "X['cost_quartile'] = pd.qcut(X['cost'], q=4, labels=False, duplicates='drop')\n",
    "\n",
    "\n",
    "# 3. NEW: Click-Cost interaction (high-value feature)\n",
    "X['click_cost_interaction'] = X['click'] * X['cost']\n",
    "\n",
    "\n",
    "# 4. NEW: Campaign click rate\n",
    "campaign_click_rate = df.groupby('campaign')['click'].mean()\n",
    "X['campaign_click_rate'] = X['campaign'].map(campaign_click_rate)\n",
    "\n",
    "\n",
    "# 5. NEW: Cost efficiency ratio\n",
    "X['cost_efficiency'] = X['cost'] / (X['cpo'] + 1)  # +1 to avoid division by zero\n",
    "\n",
    "\n",
    "# 6. NEW: Category interaction features\n",
    "X['cat1_cat2_interaction'] = X['cat1'].astype(str) + '_' + X['cat2'].astype(str)\n",
    "X['cat3_cat4_interaction'] = X['cat3'].astype(str) + '_' + X['cat4'].astype(str)\n",
    "\n",
    "\n",
    "print(f\"Total features: {X.shape[1]} (12 base + 7 advanced engineered)\")\n",
    "\n",
    "\n",
    "# Encode categorical features\n",
    "print(\"   Encoding categorical features...\")\n",
    "categorical_features = [\n",
    "    'campaign', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat8', 'cat9',\n",
    "    'cat1_cat2_interaction', 'cat3_cat4_interaction'\n",
    "]\n",
    "\n",
    "\n",
    "label_encoders = {}\n",
    "for feature in categorical_features:\n",
    "    if feature in X.columns:\n",
    "        le = LabelEncoder()\n",
    "        X[feature] = le.fit_transform(X[feature].astype(str))\n",
    "        label_encoders[feature] = le\n",
    "\n",
    "\n",
    "print(f\"Encoded {len(categorical_features)} categorical features\")\n",
    "\n",
    "\n",
    "# Clean up memory\n",
    "del df\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3. STRATIFIED TRAIN-TEST SPLIT\n",
    "# =============================================================================\n",
    "print(f\"\\nCreating stratified train-test split...\")\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"   Training set: {len(X_train):,} samples ({y_train.mean():.2%} attribution)\")\n",
    "print(f\"   Test set: {len(X_test):,} samples ({y_test.mean():.2%} attribution)\")\n",
    "\n",
    "\n",
    "# Calculate precise class imbalance\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"   Class imbalance ratio: {scale_pos_weight:.1f}:1\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4. BASELINE REPRODUCTION\n",
    "# =============================================================================\n",
    "print(f\"\\nReproducing baseline performance...\")\n",
    "\n",
    "\n",
    "baseline_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,  # Same as baseline\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric='auc'\n",
    ")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "baseline_model.fit(X_train, y_train)\n",
    "baseline_time = time.time() - start_time\n",
    "\n",
    "\n",
    "# Baseline evaluation\n",
    "y_pred_baseline = baseline_model.predict(X_test)\n",
    "y_pred_proba_baseline = baseline_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "baseline_metrics = {\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_proba_baseline),\n",
    "    'precision': precision_score(y_test, y_pred_baseline),\n",
    "    'recall': recall_score(y_test, y_pred_baseline),\n",
    "    'f1_score': f1_score(y_test, y_pred_baseline),\n",
    "    'training_time': baseline_time\n",
    "}\n",
    "\n",
    "\n",
    "print(f\"Baseline Performance (to beat):\")\n",
    "print(f\"   ROC-AUC: {baseline_metrics['roc_auc']:.3f} (target: >0.955)\")\n",
    "print(f\"   Precision: {baseline_metrics['precision']:.1%} (target: >18%)\")\n",
    "print(f\"   Recall: {baseline_metrics['recall']:.1%} (target: >90%)\")\n",
    "print(f\"   F1-Score: {baseline_metrics['f1_score']:.3f} (target: >0.30)\")\n",
    "print(f\"   Training Time: {baseline_metrics['training_time']:.1f}s\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 5. ADVANCED HYPERPARAMETER OPTIMIZATION\n",
    "# =============================================================================\n",
    "print(f\"\\nADVANCED HYPERPARAMETER OPTIMIZATION\")\n",
    "print(\"=\" * 50)\n",
    "print(\"STRATEGY: Precision-focused optimization while maintaining recall\")\n",
    "\n",
    "\n",
    "# Expanded parameter grid for superior performance\n",
    "param_distributions = {\n",
    "    # Boosting parameters - more aggressive for better performance\n",
    "    'n_estimators': [300, 500, 800, 1000],  # More trees for complex patterns\n",
    "    'max_depth': [8, 10, 12, 15],           # Deeper trees for interactions\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15], # Include slower learning\n",
    "    \n",
    "    # Sampling parameters - critical for imbalanced data\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'colsample_bylevel': [0.7, 0.8, 0.9],\n",
    "    \n",
    "    # Regularization - prevent overfitting on large dataset\n",
    "    'reg_alpha': [0, 0.01, 0.1, 0.5, 1.0],\n",
    "    'reg_lambda': [0, 0.01, 0.1, 0.5, 1.0, 2.0],\n",
    "    \n",
    "    # Tree constraints\n",
    "    'min_child_weight': [1, 3, 5, 10],\n",
    "    'max_delta_step': [0, 1, 5],  # Can help with extreme imbalance\n",
    "    \n",
    "    # Class imbalance handling - fine-tuned\n",
    "    'scale_pos_weight': [\n",
    "        scale_pos_weight * 0.7,  # Less aggressive\n",
    "        scale_pos_weight * 0.8,\n",
    "        scale_pos_weight * 0.9,\n",
    "        scale_pos_weight,        # Calculated value\n",
    "        scale_pos_weight * 1.1,\n",
    "        scale_pos_weight * 1.2,\n",
    "        scale_pos_weight * 1.3   # More aggressive\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "total_combinations = np.prod([len(v) for v in param_distributions.values()])\n",
    "print(f\"Advanced search space: {total_combinations:,} combinations\")\n",
    "print(f\"   Testing 50 iterations with 3-fold cross-validation\")\n",
    "\n",
    "\n",
    "# Advanced XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    random_state=42,\n",
    "    n_jobs=1,\n",
    "    eval_metric='auc',\n",
    "    tree_method='hist',  # Faster for large datasets\n",
    "    grow_policy='lossguide'  # Better for complex patterns\n",
    ")\n",
    "\n",
    "\n",
    "# Cross-validation strategy\n",
    "cv_strategy = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# Custom scoring function that prioritizes precision while maintaining recall\n",
    "def custom_f1_scorer(y_true, y_pred):\n",
    "    \"\"\"Custom scorer that weights precision higher\"\"\"\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    # F-beta score with beta=0.5 (weights precision 2x more than recall)\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    f_beta = (1 + 0.5**2) * (precision * recall) / ((0.5**2 * precision) + recall)\n",
    "    return f_beta\n",
    "\n",
    "\n",
    "# Advanced randomized search\n",
    "print(\"Starting advanced hyperparameter optimization...\")\n",
    "print(\"   This will take 20-40 minutes for complete dataset...\")\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,  # More iterations for better results\n",
    "    cv=cv_strategy,\n",
    "    scoring='f1',  # Standard F1 for balanced optimization\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=2  # More verbose output\n",
    ")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "random_search.fit(X_train, y_train)\n",
    "optimization_time = time.time() - start_time\n",
    "\n",
    "\n",
    "print(f\"Advanced optimization completed in {optimization_time/60:.1f} minutes\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 6. OPTIMIZED MODEL EVALUATION\n",
    "# =============================================================================\n",
    "print(f\"\\nOPTIMIZED MODEL RESULTS...\")\n",
    "\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "\n",
    "print(f\"Best Parameters Found:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"   • {param}: {value}\")\n",
    "\n",
    "\n",
    "# Evaluate optimized model\n",
    "y_pred_optimized = best_model.predict(X_test)\n",
    "y_pred_proba_optimized = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "optimized_metrics = {\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_proba_optimized),\n",
    "    'precision': precision_score(y_test, y_pred_optimized),\n",
    "    'recall': recall_score(y_test, y_pred_optimized),\n",
    "    'f1_score': f1_score(y_test, y_pred_optimized),\n",
    "    'cv_score': random_search.best_score_\n",
    "}\n",
    "\n",
    "\n",
    "print(f\"\\nOPTIMIZED PERFORMANCE:\")\n",
    "print(f\"   ROC-AUC: {optimized_metrics['roc_auc']:.3f}\")\n",
    "print(f\"   CV F1-Score: {optimized_metrics['cv_score']:.3f}\")\n",
    "print(f\"   Precision: {optimized_metrics['precision']:.1%}\")\n",
    "print(f\"   Recall: {optimized_metrics['recall']:.1%}\")\n",
    "print(f\"   F1-Score: {optimized_metrics['f1_score']:.3f}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 7. PERFORMANCE COMPARISON VS BASELINE\n",
    "# =============================================================================\n",
    "print(f\"\\nPERFORMANCE COMPARISON VS BASELINE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Metric':<12} {'Baseline':<12} {'Optimized':<12} {'Improvement':<12} {'Target Met'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# Define targets\n",
    "targets = {\n",
    "    'roc_auc': 0.955,\n",
    "    'precision': 0.18,\n",
    "    'recall': 0.90,\n",
    "    'f1_score': 0.30\n",
    "}\n",
    "\n",
    "\n",
    "improvements = {}\n",
    "targets_met = {}\n",
    "\n",
    "\n",
    "for metric in ['roc_auc', 'precision', 'recall', 'f1_score']:\n",
    "    baseline_val = baseline_metrics[metric]\n",
    "    optimized_val = optimized_metrics[metric]\n",
    "    improvement = ((optimized_val - baseline_val) / baseline_val) * 100\n",
    "    improvements[metric] = improvement\n",
    "    \n",
    "    target_met = \"YES\" if optimized_val >= targets[metric] else \"NO\"\n",
    "    targets_met[metric] = optimized_val >= targets[metric]\n",
    "    \n",
    "    print(f\"{metric.upper():<12} {baseline_val:<12.3f} {optimized_val:<12.3f} {improvement:+8.1f}% {target_met}\")\n",
    "\n",
    "\n",
    "# Overall success assessment\n",
    "targets_achieved = sum(targets_met.values())\n",
    "print(f\"\\nTARGETS ACHIEVED: {targets_achieved}/4\")\n",
    "\n",
    "\n",
    "if targets_achieved >= 3:\n",
    "    print(\"OPTIMIZATION SUCCESSFUL! Significant improvement achieved.\")\n",
    "elif targets_achieved >= 2:\n",
    "    print(\"OPTIMIZATION GOOD! Moderate improvement achieved.\")\n",
    "else:\n",
    "    print(\"OPTIMIZATION PARTIAL! Some improvement but targets not fully met.\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 8. DETAILED CONFUSION MATRIX ANALYSIS\n",
    "# =============================================================================\n",
    "print(f\"\\nDETAILED CONFUSION MATRIX ANALYSIS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "\n",
    "cm_baseline = confusion_matrix(y_test, y_pred_baseline)\n",
    "cm_optimized = confusion_matrix(y_test, y_pred_optimized)\n",
    "\n",
    "\n",
    "print(f\"BASELINE CONFUSION MATRIX:\")\n",
    "print(f\"   True Negatives:  {cm_baseline[0,0]:,}\")\n",
    "print(f\"   False Positives: {cm_baseline[0,1]:,}\")\n",
    "print(f\"   False Negatives: {cm_baseline[1,0]:,}\")\n",
    "print(f\"   True Positives:  {cm_baseline[1,1]:,}\")\n",
    "\n",
    "\n",
    "print(f\"\\nOPTIMIZED CONFUSION MATRIX:\")\n",
    "print(f\"   True Negatives:  {cm_optimized[0,0]:,}\")\n",
    "print(f\"   False Positives: {cm_optimized[0,1]:,}\")\n",
    "print(f\"   False Negatives: {cm_optimized[1,0]:,}\")\n",
    "print(f\"   True Positives:  {cm_optimized[1,1]:,}\")\n",
    "\n",
    "\n",
    "# Attribution improvement analysis\n",
    "tp_improvement = cm_optimized[1,1] - cm_baseline[1,1]\n",
    "fp_change = cm_optimized[0,1] - cm_baseline[0,1]\n",
    "\n",
    "\n",
    "print(f\"\\nATTRIBUTION PREDICTIONS IMPROVEMENT:\")\n",
    "print(f\"   Additional True Positives: {tp_improvement:,}\")\n",
    "print(f\"   Change in False Positives: {fp_change:,}\")\n",
    "\n",
    "\n",
    "if cm_baseline[1,1] > 0:\n",
    "    tp_percent_improvement = (tp_improvement / cm_baseline[1,1]) * 100\n",
    "    print(f\"   True Positive improvement: {tp_percent_improvement:+.1f}%\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 9. ADVANCED FEATURE IMPORTANCE\n",
    "# =============================================================================\n",
    "print(f\"\\nADVANCED FEATURE IMPORTANCE ANALYSIS:\")\n",
    "\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "\n",
    "print(f\"\\nTop 15 Most Important Features:\")\n",
    "for i, (_, row) in enumerate(feature_importance.head(15).iterrows(), 1):\n",
    "    print(f\"   {i:2d}. {row['feature']:<25} {row['importance']:>8.3f}\")\n",
    "\n",
    "\n",
    "# Compare with baseline top features\n",
    "print(f\"\\nNEW ENGINEERED FEATURES IMPACT:\")\n",
    "engineered_features = [\n",
    "    'click_cost_interaction', 'campaign_click_rate', 'cost_efficiency',\n",
    "    'cat1_cat2_interaction', 'cat3_cat4_interaction'\n",
    "]\n",
    "\n",
    "\n",
    "for feature in engineered_features:\n",
    "    if feature in feature_importance['feature'].values:\n",
    "        importance = feature_importance[feature_importance['feature'] == feature]['importance'].iloc[0]\n",
    "        rank = feature_importance[feature_importance['feature'] == feature].index[0] + 1\n",
    "        print(f\"   {feature:<25} Rank: {rank:2d}, Importance: {importance:.3f}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 10. BUSINESS IMPACT ANALYSIS\n",
    "# =============================================================================\n",
    "print(f\"\\nBUSINESS IMPACT ANALYSIS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "\n",
    "# Calculate business metrics\n",
    "total_test_impressions = len(y_test)\n",
    "baseline_attributions = cm_baseline[1,1]\n",
    "optimized_attributions = cm_optimized[1,1]\n",
    "additional_attributions = optimized_attributions - baseline_attributions\n",
    "\n",
    "\n",
    "# Revenue impact (assuming $50 per attribution)\n",
    "avg_revenue_per_attribution = 50\n",
    "additional_revenue = additional_attributions * avg_revenue_per_attribution\n",
    "\n",
    "\n",
    "# Cost impact (false positives cost money)\n",
    "baseline_fp_cost = cm_baseline[0,1] * 5  # $5 per false positive\n",
    "optimized_fp_cost = cm_optimized[0,1] * 5\n",
    "cost_change = optimized_fp_cost - baseline_fp_cost\n",
    "\n",
    "\n",
    "net_revenue_impact = additional_revenue - cost_change\n",
    "\n",
    "\n",
    "print(f\"Business Impact Metrics:\")\n",
    "print(f\"   Test impressions: {total_test_impressions:,}\")\n",
    "print(f\"   Baseline attributions: {baseline_attributions:,}\")\n",
    "print(f\"   Optimized attributions: {optimized_attributions:,}\")\n",
    "print(f\"   Additional attributions: {additional_attributions:,}\")\n",
    "print(f\"   Additional revenue: ${additional_revenue:,}\")\n",
    "print(f\"   Cost change (FP): ${cost_change:,}\")\n",
    "print(f\"   Net revenue impact: ${net_revenue_impact:,}\")\n",
    "\n",
    "\n",
    "if baseline_attributions > 0:\n",
    "    attribution_lift = (additional_attributions / baseline_attributions) * 100\n",
    "    print(f\"   Attribution lift: {attribution_lift:+.1f}%\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 11. SAVE COMPREHENSIVE RESULTS\n",
    "# =============================================================================\n",
    "print(f\"\\nSaving comprehensive optimization results...\")\n",
    "\n",
    "\n",
    "# Complete results dictionary\n",
    "results = {\n",
    "    'optimization_info': {\n",
    "        'dataset_size': len(X),\n",
    "        'complete_dataset': True,\n",
    "        'attribution_rate': y.mean(),\n",
    "        'optimization_time_minutes': optimization_time / 60,\n",
    "        'search_iterations': 50,\n",
    "        'cv_folds': 3,\n",
    "        'advanced_features': True\n",
    "    },\n",
    "    'targets': targets,\n",
    "    'targets_achieved': {k: bool(v) for k, v in targets_met.items()},\n",
    "    'targets_met_count': targets_achieved,\n",
    "    'best_parameters': best_params,\n",
    "    'baseline_performance': baseline_metrics,\n",
    "    'optimized_performance': optimized_metrics,\n",
    "    'improvements': improvements,\n",
    "    'feature_importance': feature_importance.to_dict('records'),\n",
    "    'engineered_features_impact': {\n",
    "        feature: {\n",
    "            'importance': float(feature_importance[feature_importance['feature'] == feature]['importance'].iloc[0])\n",
    "            if feature in feature_importance['feature'].values else 0,\n",
    "            'rank': int(feature_importance[feature_importance['feature'] == feature].index[0] + 1)\n",
    "            if feature in feature_importance['feature'].values else len(feature_importance)\n",
    "        }\n",
    "        for feature in engineered_features\n",
    "    },\n",
    "    'business_impact': {\n",
    "        'additional_attributions': int(additional_attributions),\n",
    "        'attribution_lift_percent': float(attribution_lift) if baseline_attributions > 0 else 0,\n",
    "        'additional_revenue': float(additional_revenue),\n",
    "        'cost_change': float(cost_change),\n",
    "        'net_revenue_impact': float(net_revenue_impact)\n",
    "    },\n",
    "    'confusion_matrices': {\n",
    "        'baseline': cm_baseline.tolist(),\n",
    "        'optimized': cm_optimized.tolist()\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Save results\n",
    "with open('xgboost_complete_optimization_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2, default=str)\n",
    "\n",
    "\n",
    "feature_importance.to_csv('xgboost_complete_feature_importance.csv', index=False)\n",
    "\n",
    "\n",
    "# Save model parameters for production\n",
    "production_config = {\n",
    "    'model_class': 'XGBClassifier',\n",
    "    'parameters': best_params,\n",
    "    'performance': optimized_metrics,\n",
    "    'feature_names': list(X.columns),\n",
    "    'label_encoders': {k: list(v.classes_) for k, v in label_encoders.items()}\n",
    "}\n",
    "\n",
    "\n",
    "with open('xgboost_production_config.json', 'w') as f:\n",
    "    json.dump(production_config, f, indent=2, default=str)\n",
    "\n",
    "\n",
    "print(\"Comprehensive results saved:\")\n",
    "print(\"   • xgboost_complete_optimization_results.json\")\n",
    "print(\"   • xgboost_complete_feature_importance.csv\")\n",
    "print(\"   • xgboost_production_config.json\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 12. FINAL PRODUCTION RECOMMENDATIONS\n",
    "# =============================================================================\n",
    "print(f\"\\nFINAL PRODUCTION RECOMMENDATIONS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "\n",
    "if targets_achieved >= 3:\n",
    "    print(\"DEPLOY OPTIMIZED MODEL IMMEDIATELY\")\n",
    "    print(f\"   • Achieved {targets_achieved}/4 performance targets\")\n",
    "    print(f\"   • ROC-AUC: {optimized_metrics['roc_auc']:.3f} (vs baseline {baseline_metrics['roc_auc']:.3f})\")\n",
    "    print(f\"   • Precision: {optimized_metrics['precision']:.1%} (vs baseline {baseline_metrics['precision']:.1%})\")\n",
    "    print(f\"   • Additional revenue: ${additional_revenue:,}\")\n",
    "elif targets_achieved >= 2:\n",
    "    print(\"DEPLOY WITH MONITORING\")\n",
    "    print(f\"   • Achieved {targets_achieved}/4 performance targets\")\n",
    "    print(f\"   • Significant improvement over baseline\")\n",
    "    print(f\"   • Monitor performance closely in production\")\n",
    "else:\n",
    "    print(\"FURTHER OPTIMIZATION RECOMMENDED\")\n",
    "    print(f\"   • Only achieved {targets_achieved}/4 performance targets\")\n",
    "    print(f\"   • Consider ensemble methods or deep learning\")\n",
    "\n",
    "\n",
    "print(f\"\\nProduction-Ready Configuration:\")\n",
    "print(\"```python\")\n",
    "print(\"xgb.XGBClassifier(\")\n",
    "for param, value in best_params.items():\n",
    "    if isinstance(value, str):\n",
    "        print(f\"    {param}='{value}',\")\n",
    "    else:\n",
    "        print(f\"    {param}={value},\")\n",
    "print(\"    random_state=42,\")\n",
    "print(\"    n_jobs=-1,\")\n",
    "print(\"    eval_metric='auc',\")\n",
    "print(\"    tree_method='hist',\")\n",
    "print(\"    grow_policy='lossguide'\")\n",
    "print(\")\")\n",
    "print(\"```\")\n",
    "\n",
    "\n",
    "print(f\"\\nExpected Production Performance:\")\n",
    "print(f\"   • ROC-AUC: {optimized_metrics['roc_auc']:.3f}\")\n",
    "print(f\"   • Precision: {optimized_metrics['precision']:.1%}\")\n",
    "print(f\"   • Recall: {optimized_metrics['recall']:.1%}\")\n",
    "print(f\"   • F1-Score: {optimized_metrics['f1_score']:.3f}\")\n",
    "print(f\"   • Training time: ~{optimization_time/60:.0f} minutes for full dataset\")\n",
    "\n",
    "\n",
    "print(f\"\\nKey Success Factors:\")\n",
    "print(f\"   • Advanced feature engineering with {len(engineered_features)} new features\")\n",
    "print(f\"   • Optimized for complete {len(X):,} sample dataset\")\n",
    "print(f\"   • Fine-tuned class imbalance handling\")\n",
    "print(f\"   • Production-ready configuration with robust parameters\")\n",
    "\n",
    "\n",
    "print(f\"\\nXGBOOST COMPLETE DATASET OPTIMIZATION COMPLETED!\")\n",
    "print(f\"Successfully optimized for maximum Criteo attribution predictions!\")\n",
    "print(f\"Ready for production deployment on 16.4M+ impression dataset!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f19c69a-8e58-4abe-a702-096104d728ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SAVE MODEL TO PICKLE FILE\n",
    "# =============================================================================\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\nSAVING TRAINED MODEL...\")\n",
    "\n",
    "# Model metadata\n",
    "model_info = {\n",
    "    'model_name': 'XGBoost_Criteo_Attribution_Baseline',\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'dataset_size': len(X_train),\n",
    "    'features': list(X.columns),\n",
    "    'performance': baseline_metrics,\n",
    "    'parameters': baseline_model.get_params(),\n",
    "    'label_encoders': {k: list(v.classes_) for k, v in label_encoders.items()}\n",
    "}\n",
    "\n",
    "# Save the model\n",
    "model_filename = 'criteo_attribution_xgboost_model.pkl'\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': baseline_model,\n",
    "        'label_encoders': label_encoders,\n",
    "        'feature_names': list(X.columns),\n",
    "        'metadata': model_info\n",
    "    }, f)\n",
    "\n",
    "print(f\"Model saved successfully: {model_filename}\")\n",
    "print(f\"   Model type: XGBoost Classifier\")\n",
    "print(f\"   Features: {len(X.columns)}\")\n",
    "print(f\"   ROC-AUC: {baseline_metrics['roc_auc']:.3f}\")\n",
    "print(f\"   Precision: {baseline_metrics['precision']:.1%}\")\n",
    "print(f\"   Recall: {baseline_metrics['recall']:.1%}\")\n",
    "\n",
    "# Also save metadata separately for easy reference\n",
    "import json\n",
    "with open('criteo_model_metadata.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nMetadata saved: criteo_model_metadata.json\")\n",
    "\n",
    "# Optional: Test loading the model\n",
    "print(\"\\nTesting model loading...\")\n",
    "with open(model_filename, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "    loaded_model = loaded_data['model']\n",
    "    \n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"Model ready for production deployment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea00109-b1cc-48ce-97ea-8817a9820bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load saved model for predictions\n",
    "# import pickle\n",
    "\n",
    "# with open('criteo_attribution_xgboost_model.pkl', 'rb') as f:\n",
    "#     saved_data = pickle.load(f)\n",
    "    \n",
    "# model = saved_data['model']\n",
    "# label_encoders = saved_data['label_encoders']\n",
    "# feature_names = saved_data['feature_names']\n",
    "# metadata = saved_data['metadata']\n",
    "\n",
    "# # Make predictions\n",
    "# y_predictions = model.predict(X_new)\n",
    "# y_probabilities = model.predict_proba(X_new)[:, 1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
